\section{Conclusion}
Sim-to-real transfer in RL requires carefully addressing mismatches in observations, actions, transitions, and rewards. Organized by the OATR framework, we have reviewed the key methods and their trade-offs. Domain randomization can yield robust policies by training on diverse simulated variations, while system identification and adaptive methods use real data to fine-tune the simulation. Our discussion and selected examples from the literature highlight both the progress made (e.g.\ OpenAI’s ADR, Tan et al.’s locomotion) and the remaining challenges (e.g.\ reward gaps, irreducible dynamics differences). By critically evaluating each approach, we hope to provide a clear resource for researchers to design \simtoreal pipelines. Ongoing research will continue to blend these techniques and exploit new ideas (like learned simulators or real-time adaptation) to further bridge the reality gap.